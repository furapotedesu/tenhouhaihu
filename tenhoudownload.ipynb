{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN3Q1LD8A4dCe6HSd0fbCAt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# =========================================================\n","# âœ… 0. å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n","# =========================================================\n","!pip -q install mahjong pytest requests beautifulsoup4\n","\n","# =========================================================\n","# âœ… 1. å…±é€šã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n","# =========================================================\n","import os, sys, re, time, urllib.parse, zipfile, shutil, gzip\n","import requests\n","from bs4 import BeautifulSoup\n","from google.colab import files, drive\n","\n","# =========================================================\n","# âœ… 2. Google Drive ã‚’ãƒã‚¦ãƒ³ãƒˆ\n","# =========================================================\n","drive.mount('/content/drive')\n","\n","# =========================================================\n","# âœ… 3. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ ¼ç´ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ\n","# =========================================================\n","module_dir = '/content/drive/MyDrive/my_modules'\n","os.makedirs(module_dir, exist_ok=True)\n","\n","# =========================================================\n","# âœ… 4. GitHub ã‹ã‚‰å¿…è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¦é…ç½®\n","# =========================================================\n","files_to_get = [\n","    \"__init__.py\",\n","    \"analyzer.py\",\n","    \"converters.py\",\n","    \"display_agari_fixed.py\",\n","    \"display_call.py\",\n","    \"display_discard_hand_at.py\",\n","    \"display_dora_fixed.py\",\n","    \"display_handflow.py\",\n","    \"display_reach_fixed.py\",\n","    \"display_ryuukyoku.py\",\n","    \"mahjong_py.html\",\n","    \"parser.py\",\n","    \"shanten_calc.py\",\n","    \"splitter.py\",\n","    \"utils.py\",\n","    # --- tests ---\n","    \"test_analyzer.py\",\n","    \"test_converters.py\",\n","    \"test_display_agari_fixed.py\",\n","    \"test_display_call.py\",\n","    \"test_display_discard_hand_at.py\",\n","    \"test_display_dora_fixed.py\",\n","    \"test_display_handflow.py\",\n","    \"test_display_reach_fixed.py\",\n","    \"test_display_ryuukyoku_info.py\",\n","    \"test_init.py\",\n","    \"test_parser.py\",\n","    \"test_shanten_calc.py\",\n","    \"test_splitter.py\"\n","]\n","\n","base_url = \"https://raw.githubusercontent.com/furapotedesu/tenhouhaihu/main/\"\n","for fname in files_to_get:\n","    !wget -q {base_url}{fname} -O {fname}\n","    !mv {fname} {module_dir}/\n","\n","# =========================================================\n","# âœ… 5. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ¤œç´¢ãƒ‘ã‚¹ã‚’è¿½åŠ \n","# =========================================================\n","sys.path.append(module_dir)\n","\n","# =========================================================\n","# âœ… 6. pytest ã‚’å®Ÿè¡Œï¼ˆtests ãƒ•ã‚©ãƒ«ãƒ€å…¨ä½“ï¼‰\n","# =========================================================\n","!PYTHONPATH=\"{module_dir}\" pytest {module_dir}/tests --maxfail=1 --disable-warnings -q\n","\n","\n","# ================= é¸æŠUI =================\n","print(\"ã©ã®æ–¹æ³•ã§ç‰Œè­œãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã‹ï¼Ÿ\")\n","print(\"ã„ï¼šHTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹\")\n","print(\"ã‚ï¼šå¹´åº¦åˆ¥ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹\")\n","print(\"ã¯ï¼šæœ€è¿‘ã®ç‰Œè­œï¼ˆlist.cgiï¼‰ã‚’å–å¾—ã™ã‚‹\")\n","\n","choice = \"\"\n","while choice not in {\"ã„\", \"ã‚\", \"ã¯\"}:\n","    choice = input(\"é¸æŠè‚¢ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆã„ãƒ»ã‚ãƒ»ã¯ï¼‰ï¼š\").strip()\n","\n","# ================= ã€Œã„ã€é¸æŠæ™‚ï¼šHTMLã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç† =================\n","if choice == \"ã„\":\n","    print(\"ğŸ“‚ HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼štenhou_logs.htmlï¼‰\")\n","    uploaded = files.upload()\n","    html_filename = list(uploaded.keys())[0]\n","\n","    with open(html_filename, 'r', encoding='utf-8') as f:\n","        soup = BeautifulSoup(f, 'html.parser')\n","\n","    links = set()\n","    for a in soup.find_all('a', href=True):\n","        href = a['href']\n","        if href.startswith(\"https://tenhou.net/\"):\n","            links.add(href)\n","\n","    links = sorted(links)\n","    print(f\"âœ… tenhouãƒªãƒ³ã‚¯æŠ½å‡ºå®Œäº†ï¼š{len(links)} ä»¶\")\n","\n","    with open(\"converted_links.txt\", \"w\", encoding=\"utf-8\") as f:\n","        for url in links:\n","            f.write(url + \"\\n\")\n","\n","    print(\"âœ… converted_links.txt ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆã“ã®å¾Œ STEP3ã€œ5 ã«è‡ªå‹•æ¥ç¶šï¼‰\")\n","\n","# ================= ã€Œã‚ã€é¸æŠæ™‚ï¼šå¹´åº¦åˆ¥ZIPå‡¦ç† =================\n","elif choice == \"ã‚\":\n","    year = input(\"ä½•å¹´ã®ç‰Œè­œã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã‹ï¼Ÿï¼ˆä¾‹ï¼š2023ï¼‰ï¼š\").strip()\n","    filename = f\"scraw{year}.zip\"\n","    url = f\"https://tenhou.net/sc/raw/{filename}\"\n","\n","    save_dir = f\"tenhou_logs_{year}\"\n","    os.makedirs(save_dir, exist_ok=True)\n","    zip_path = os.path.join(save_dir, filename)\n","\n","    print(f\"â¬‡ï¸ {filename} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...\")\n","    r = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n","\n","    if r.status_code == 200 and len(r.content) > 1000:\n","        with open(zip_path, \"wb\") as f:\n","            f.write(r.content)\n","        print(f\"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼š{zip_path}\")\n","    else:\n","        raise Exception(f\"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•— or ç©ºãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ{r.status_code}ï¼‰\")\n","\n","    extract_dir = os.path.join(save_dir, \"unpacked\")\n","    os.makedirs(extract_dir, exist_ok=True)\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_dir)\n","    print(f\"âœ… è§£å‡å®Œäº†ï¼š{extract_dir}\")\n","\n","    html_dir = os.path.join(extract_dir, \"htmls\")\n","    os.makedirs(html_dir, exist_ok=True)\n","    count = 0\n","\n","    for root, _, files_in_dir in os.walk(extract_dir):\n","        for file in files_in_dir:\n","            if file.startswith(\"scc\") and file.endswith(\".gz\"):\n","                gz_path = os.path.join(root, file)\n","                out_path = os.path.join(html_dir, file[:-3])\n","                with gzip.open(gz_path, 'rb') as f_in, open(out_path, 'wb') as f_out:\n","                    shutil.copyfileobj(f_in, f_out)\n","                    count += 1\n","\n","    print(f\"âœ… {count} ä»¶ã® .gz ã‚’ .html ã«å¤‰æ›\")\n","\n","    raw_links = []\n","    pattern = r\"https?://tenhou\\.net/0/\\?log=[\\w\\-]+\"\n","    for file in os.listdir(html_dir):\n","        if file.endswith(\".html\"):\n","            path = os.path.join(html_dir, file)\n","            with open(path, encoding=\"utf-8\", errors=\"ignore\") as f:\n","                text = f.read()\n","                found = re.findall(pattern, text)\n","                raw_links.extend(found)\n","\n","    print(f\"âœ… ãƒªãƒ³ã‚¯æŠ½å‡ºï¼š{len(raw_links)} ä»¶\")\n","\n","    with open(\"converted_links.txt\", \"w\", encoding=\"utf-8\") as f:\n","        for url in raw_links:\n","            f.write(url + \"\\n\")\n","\n","    print(\"âœ… converted_links.txt ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆã“ã®å¾Œ STEP3ã€œ5 ã«è‡ªå‹•æ¥ç¶šï¼‰\")\n","\n","# ================= ã€Œã¯ã€é¸æŠæ™‚ï¼šlist.cgi ã‹ã‚‰ .gz ã‚’å‡¦ç† =================\n","elif choice == \"ã¯\":\n","    print(\"æœ€è¿‘ã®ç‰Œè­œã®ã©ã¡ã‚‰ã‚’å–å¾—ã—ã¾ã™ã‹ï¼Ÿ\")\n","    print(\"1ï¼šç›´è¿‘7æ—¥é–“ã®ãƒªã‚¹ãƒˆ\")\n","    print(\"2ï¼šå…¨éå»åˆ†ï¼ˆlist.cgi?oldï¼‰\")\n","    list_choice = \"\"\n","    while list_choice not in {\"1\", \"2\"}:\n","        list_choice = input(\"é¸æŠè‚¢ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ1 ã¾ãŸã¯ 2ï¼‰ï¼š\").strip()\n","\n","    base_url = \"https://tenhou.net/sc/raw/\"\n","    if list_choice == \"1\":\n","        list_url = base_url + \"list.cgi\"\n","        list_name = \"tenhou_list_current.txt\"\n","    else:\n","        list_url = base_url + \"list.cgi?old\"\n","        list_name = \"tenhou_list_old.txt\"\n","\n","    print(f\"â¬‡ï¸ {list_url} ã‚’å–å¾—ä¸­...\")\n","    r = requests.get(list_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n","    if r.status_code != 200 or len(r.text) < 1000:\n","        raise Exception(\"âŒ listå–å¾—å¤±æ•—\")\n","\n","    with open(list_name, \"w\", encoding=\"utf-8\") as f:\n","        f.write(r.text)\n","\n","    print(f\"âœ… listä¿å­˜å®Œäº†ï¼š{list_name}\")\n","\n","    # âœ… ç¾åœ¨ã®listå½¢å¼ã«åˆã£ãŸæ­£è¦è¡¨ç¾ã§æŠ½å‡º\n","    with open(list_name, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n","        text = f.read()\n","\n","    matches = re.findall(r\"file:'(scc\\d{10}\\.html\\.gz)'\", text)\n","    gz_files = sorted(set(matches))\n","    print(f\"âœ… sccãƒ•ã‚¡ã‚¤ãƒ«æ•°ï¼š{len(gz_files)} ä»¶ï¼ˆä¾‹ï¼š{gz_files[:3]})\")\n","\n","    # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™\n","    os.makedirs(\"list_mode/htmls\", exist_ok=True)\n","    converted_links = []\n","\n","    for filename in gz_files:                     # â† â˜…ã‚³ãƒ­ãƒ³ã‚’è¿½åŠ â˜…\n","        gz_url = f\"{base_url}dat/{filename}\"      # âœ… å¹´ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãªã—\n","        local_gz = filename\n","        local_html = filename[:-3]\n","\n","        try:\n","            r = requests.get(gz_url, headers={\"User-Agent\": \"Mozilla/5.0\"}, timeout=10)\n","\n","            if r.status_code != 200:\n","                print(f\"âš ï¸ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆHTTP {r.status_code}ï¼‰ï¼š{gz_url}\")\n","                continue\n","\n","            if len(r.content) < 500:\n","                print(f\"âš ï¸ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå°ã•ã™ãã‚‹ï¼‰ï¼š{gz_url}ï¼ˆ{len(r.content)} bytesï¼‰\")\n","                continue\n","\n","            with open(local_gz, \"wb\") as f:\n","                f.write(r.content)\n","            print(f\"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸï¼š{gz_url}\")\n","\n","            with gzip.open(local_gz, \"rb\") as f_in, open(local_html, \"wb\") as f_out:\n","                shutil.copyfileobj(f_in, f_out)\n","            print(f\"âœ… è§£å‡æˆåŠŸï¼š{local_html}\")\n","\n","            with open(local_html, encoding=\"utf-8\", errors=\"ignore\") as f:\n","                html = f.read()\n","\n","            found = re.findall(r\"https?://tenhou\\.net/0/\\?log=[\\w\\-]+\", html)\n","            if found:\n","                print(f\"âœ… ãƒ­ã‚°æŠ½å‡ºæˆåŠŸï¼ˆ{filename}ï¼‰ï¼š{len(found)} ä»¶\")\n","                converted_links.extend(found)\n","\n","            os.remove(local_gz)\n","            os.remove(local_html)\n","\n","        except Exception as e:\n","            print(f\"âš ï¸ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {filename} â†’ {e}\")\n","\n","    # URLä¿å­˜\n","    with open(\"converted_links.txt\", \"w\", encoding=\"utf-8\") as f:\n","        for url in converted_links:\n","            if url.startswith(\"http\"):\n","                f.write(url + \"\\n\")\n","\n","    print(\"âœ… converted_links.txt ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆã“ã®å¾Œ STEP3ã€œ5 ã«è‡ªå‹•æ¥ç¶šï¼‰\")\n","\n","\n","# ================= STEP3ï¼šæ­£è¦åŒ– =================\n","with open(\"converted_links.txt\", \"r\", encoding=\"utf-8\") as f:\n","    raw_links = [\n","        line.strip()\n","        for line in f\n","        if line.strip().startswith(\"http\") and \"tenhou.net\" in line\n","    ]\n","\n","normalized_links = []\n","for url in raw_links:\n","    url = url.replace(\"/tenhou.net/3/\", \"/tenhou.net/0/\")\n","    url = re.sub(r\"\\?log=\", \"log/?\", url)\n","    url = re.sub(r\"&tw=[0-3]\", \"\", url)\n","    normalized_links.append(url)\n","\n","print(\"âœ… æ­£è¦åŒ–å¾Œãƒªãƒ³ã‚¯ï¼ˆä¾‹ï¼‰ï¼š\")\n","print(\"\\n\".join(normalized_links[:5]))\n","print(f\"âœ… æœ‰åŠ¹ãƒªãƒ³ã‚¯æ•°ï¼š{len(normalized_links)} ä»¶ï¼ˆå…¨ä»¶å‡¦ç†ï¼‰\")\n","\n","# ================= STEP4ï¼šmjlog ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ =================\n","output_filename = \"mjlog_all.txt\"\n","\n","with open(output_filename, \"w\", encoding=\"utf-8\") as out_file:\n","    for i, url in enumerate(normalized_links):\n","        match = re.search(r\"(?:\\?|/)log[\\/=](.+)\", url)\n","        log_id = match.group(1) if match else f\"log_{i+1}\"\n","\n","        try:\n","            response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n","            response.raise_for_status()\n","            content = response.text.strip()\n","\n","            out_file.write(content + \"\\n\")\n","            out_file.write(\"=\" * 80 + \"\\n\")\n","\n","            print(f\"âœ… [{i+1}/10] ä¿å­˜æˆåŠŸï¼š{log_id}\")\n","        except Exception as e:\n","            print(f\"âš ï¸ ã‚¨ãƒ©ãƒ¼ï¼š{log_id} â†’ {e}\")\n","\n","        time.sleep(1)\n","\n","print(f\"âœ… ä¿å­˜å®Œäº†ï¼š{output_filename}\")\n","\n","# ================= STEP5ï¼šUNã‚¿ã‚° ãƒ‡ã‚³ãƒ¼ãƒ‰ =================\n","def multi_url_decode(s, max_times=5):\n","    for _ in range(max_times):\n","        decoded = urllib.parse.unquote(s)\n","        if decoded == s:\n","            break\n","        s = decoded\n","    return s\n","\n","input_filename = output_filename\n","output_decoded = \"mjlog_all_decoded.txt\"\n","\n","with open(input_filename, \"r\", encoding=\"utf-8\") as f:\n","    content = f.read()\n","\n","logs = content.split(\"=\" * 80)\n","decoded_logs = []\n","\n","for log in logs:\n","    if \"<UN\" not in log:\n","        decoded_logs.append(log)\n","        continue\n","\n","    def replace_names(match):\n","        attr_str = match.group(1)\n","        for i in range(4):\n","            attr_str = re.sub(\n","                rf'n{i}=\"([^\"]+)\"',\n","                lambda m: f'n{i}=\"{multi_url_decode(m.group(1))}\"',\n","                attr_str\n","            )\n","        return f\"<UN {attr_str}>\"\n","\n","    log = re.sub(r\"<UN\\s+([^>]+)>\", replace_names, log)\n","    decoded_logs.append(log)\n","\n","with open(output_decoded, \"w\", encoding=\"utf-8\") as f:\n","    f.write((\"=\" * 80 + \"\\n\").join(decoded_logs))\n","\n","print(f\"ğŸ‰ å¾©å·å®Œäº†ï¼š{output_decoded}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":747},"collapsed":true,"id":"P5hRYvNTlnFp","executionInfo":{"status":"error","timestamp":1745847079927,"user_tz":-540,"elapsed":120120,"user":{"displayName":"ãƒ•ãƒ©ãƒãƒ¼ãƒ†ä¼¯çˆµ","userId":"01789154697204439459"}},"outputId":"2d4da1af-46da-4496-ab52-a8de30aeba3b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/60.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hMounted at /content/drive\n","\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                         [100%]\u001b[0m\n","\u001b[32m\u001b[32m\u001b[1m48 passed\u001b[0m\u001b[32m in 16.80s\u001b[0m\u001b[0m\n","ã©ã®æ–¹æ³•ã§ç‰Œè­œãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã‹ï¼Ÿ\n","ã„ï¼šHTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹\n","ã‚ï¼šå¹´åº¦åˆ¥ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹\n","ã¯ï¼šæœ€è¿‘ã®ç‰Œè­œï¼ˆlist.cgiï¼‰ã‚’å–å¾—ã™ã‚‹\n","é¸æŠè‚¢ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆã„ãƒ»ã‚ãƒ»ã¯ï¼‰ï¼šã‚\n","ä½•å¹´ã®ç‰Œè­œã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã‹ï¼Ÿï¼ˆä¾‹ï¼š2023ï¼‰ï¼š2023\n","â¬‡ï¸ scraw2023.zip ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...\n","âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼štenhou_logs_2023/scraw2023.zip\n","âœ… è§£å‡å®Œäº†ï¼štenhou_logs_2023/unpacked\n","âœ… 365 ä»¶ã® .gz ã‚’ .html ã«å¤‰æ›\n","âœ… ãƒªãƒ³ã‚¯æŠ½å‡ºï¼š285937 ä»¶\n","âœ… converted_links.txt ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆã“ã®å¾Œ STEP3ã€œ5 ã«è‡ªå‹•æ¥ç¶šï¼‰\n","âœ… æ­£è¦åŒ–å¾Œãƒªãƒ³ã‚¯ï¼ˆä¾‹ï¼‰ï¼š\n","http://tenhou.net/0/log/?2023052300gm-00a9-0000-1b23c717\n","http://tenhou.net/0/log/?2023052300gm-00b9-0000-4e546fc1\n","http://tenhou.net/0/log/?2023052300gm-00a9-0000-f9314edb\n","http://tenhou.net/0/log/?2023052300gm-00a9-0000-e85d55a7\n","http://tenhou.net/0/log/?2023052300gm-00a9-0000-37d2816a\n","âœ… æœ‰åŠ¹ãƒªãƒ³ã‚¯æ•°ï¼š285937 ä»¶ï¼ˆå…¨ä»¶å‡¦ç†ï¼‰\n","âœ… [1/10] ä¿å­˜æˆåŠŸï¼š?2023052300gm-00a9-0000-1b23c717\n","âœ… [2/10] ä¿å­˜æˆåŠŸï¼š?2023052300gm-00b9-0000-4e546fc1\n","âœ… [3/10] ä¿å­˜æˆåŠŸï¼š?2023052300gm-00a9-0000-f9314edb\n","âœ… [4/10] ä¿å­˜æˆåŠŸï¼š?2023052300gm-00a9-0000-e85d55a7\n","âœ… [5/10] ä¿å­˜æˆåŠŸï¼š?2023052300gm-00a9-0000-37d2816a\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-2e687308ee42>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âš ï¸ ã‚¨ãƒ©ãƒ¼ï¼š{log_id} â†’ {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âœ… ä¿å­˜å®Œäº†ï¼š{output_filename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}