{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMVsoGPA19ML1EsvNP46kTt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# ================= 共通インポート =================\n","import os\n","import re\n","import time\n","import urllib.parse\n","import requests\n","import zipfile\n","import shutil\n","import gzip\n","from bs4 import BeautifulSoup\n","from google.colab import files\n","\n","# ================= 選択UI =================\n","print(\"どの方法で牌譜データを取得しますか？\")\n","print(\"い：HTMLファイルをアップロードする\")\n","print(\"ろ：年度別ZIPファイルをダウンロードする\")\n","print(\"は：最近の牌譜（list.cgi）を取得する\")\n","\n","choice = \"\"\n","while choice not in {\"い\", \"ろ\", \"は\"}:\n","    choice = input(\"選択肢を入力してください（い・ろ・は）：\").strip()\n","\n","# ================= 「い」選択時：HTMLアップロード処理 =================\n","if choice == \"い\":\n","    print(\"📂 HTMLファイルをアップロードしてください（例：tenhou_logs.html）\")\n","    uploaded = files.upload()\n","    html_filename = list(uploaded.keys())[0]\n","\n","    with open(html_filename, 'r', encoding='utf-8') as f:\n","        soup = BeautifulSoup(f, 'html.parser')\n","\n","    links = set()\n","    for a in soup.find_all('a', href=True):\n","        href = a['href']\n","        if href.startswith(\"https://tenhou.net/\"):\n","            links.add(href)\n","\n","    links = sorted(links)\n","    print(f\"✅ tenhouリンク抽出完了：{len(links)} 件\")\n","\n","    with open(\"converted_links.txt\", \"w\", encoding=\"utf-8\") as f:\n","        for url in links:\n","            f.write(url + \"\\n\")\n","\n","    print(\"✅ converted_links.txt を保存しました（この後 STEP3〜5 に自動接続）\")\n","\n","# ================= 「ろ」選択時：年度別ZIP処理 =================\n","elif choice == \"ろ\":\n","    year = input(\"何年の牌譜をダウンロードしますか？（例：2023）：\").strip()\n","    filename = f\"scraw{year}.zip\"\n","    url = f\"https://tenhou.net/sc/raw/{filename}\"\n","\n","    save_dir = f\"tenhou_logs_{year}\"\n","    os.makedirs(save_dir, exist_ok=True)\n","    zip_path = os.path.join(save_dir, filename)\n","\n","    print(f\"⬇️ {filename} をダウンロードしています...\")\n","    r = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n","\n","    if r.status_code == 200 and len(r.content) > 1000:\n","        with open(zip_path, \"wb\") as f:\n","            f.write(r.content)\n","        print(f\"✅ ダウンロード完了：{zip_path}\")\n","    else:\n","        raise Exception(f\"❌ ダウンロード失敗 or 空ファイル（{r.status_code}）\")\n","\n","    extract_dir = os.path.join(save_dir, \"unpacked\")\n","    os.makedirs(extract_dir, exist_ok=True)\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_dir)\n","    print(f\"✅ 解凍完了：{extract_dir}\")\n","\n","    html_dir = os.path.join(extract_dir, \"htmls\")\n","    os.makedirs(html_dir, exist_ok=True)\n","    count = 0\n","\n","    for root, _, files_in_dir in os.walk(extract_dir):\n","        for file in files_in_dir:\n","            if file.startswith(\"scc\") and file.endswith(\".gz\"):\n","                gz_path = os.path.join(root, file)\n","                out_path = os.path.join(html_dir, file[:-3])\n","                with gzip.open(gz_path, 'rb') as f_in, open(out_path, 'wb') as f_out:\n","                    shutil.copyfileobj(f_in, f_out)\n","                    count += 1\n","\n","    print(f\"✅ {count} 件の .gz を .html に変換\")\n","\n","    raw_links = []\n","    pattern = r\"https?://tenhou\\.net/0/\\?log=[\\w\\-]+\"\n","    for file in os.listdir(html_dir):\n","        if file.endswith(\".html\"):\n","            path = os.path.join(html_dir, file)\n","            with open(path, encoding=\"utf-8\", errors=\"ignore\") as f:\n","                text = f.read()\n","                found = re.findall(pattern, text)\n","                raw_links.extend(found)\n","\n","    print(f\"✅ リンク抽出：{len(raw_links)} 件\")\n","\n","    with open(\"converted_links.txt\", \"w\", encoding=\"utf-8\") as f:\n","        for url in raw_links:\n","            f.write(url + \"\\n\")\n","\n","    print(\"✅ converted_links.txt を保存しました（この後 STEP3〜5 に自動接続）\")\n","\n","# ================= 「は」選択時：list.cgiから.gzを処理 =================\n","elif choice == \"は\":\n","    print(\"最近の牌譜のどちらを取得しますか？\")\n","    print(\"1：直近7日間のリスト\")\n","    print(\"2：全過去分（list.cgi?old）\")\n","    list_choice = \"\"\n","    while list_choice not in {\"1\", \"2\"}:\n","        list_choice = input(\"選択肢を入力してください（1 または 2）：\").strip()\n","\n","    base_url = \"https://tenhou.net/sc/raw/\"\n","    if list_choice == \"1\":\n","        list_url = base_url + \"list.cgi\"\n","        list_name = \"tenhou_list_current.txt\"\n","    else:\n","        list_url = base_url + \"list.cgi?old\"\n","        list_name = \"tenhou_list_old.txt\"\n","\n","    print(f\"⬇️ {list_url} を取得中...\")\n","    r = requests.get(list_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n","    if r.status_code != 200 or len(r.text) < 1000:\n","        raise Exception(\"❌ list取得失敗\")\n","\n","    with open(list_name, \"w\", encoding=\"utf-8\") as f:\n","        f.write(r.text)\n","\n","    print(f\"✅ list保存完了：{list_name}\")\n","\n","    # ✅ 現在のlist形式に合った正規表現で抽出（例：file:'scc2025040100.html.gz'）\n","    with open(list_name, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n","        text = f.read()\n","\n","    matches = re.findall(r\"file:'(scc\\d{10}\\.html\\.gz)'\", text)\n","    gz_files = sorted(set(matches))\n","    print(f\"✅ sccファイル数：{len(gz_files)} 件（例：{gz_files[:3]})\")\n","\n","    # 保存ディレクトリ準備\n","    os.makedirs(\"list_mode/htmls\", exist_ok=True)\n","    converted_links = []\n","\n","    for filename in gz_files\n","        gz_url = f\"{base_url}dat/{filename}\"  # ✅ 年ディレクトリなし\n","        local_gz = filename\n","        local_html = filename[:-3]\n","\n","        try:\n","            r = requests.get(gz_url, headers={\"User-Agent\": \"Mozilla/5.0\"}, timeout=10)\n","\n","            if r.status_code != 200:\n","                print(f\"⚠️ スキップ（HTTP {r.status_code}）：{gz_url}\")\n","                continue\n","\n","            if len(r.content) < 500:\n","                print(f\"⚠️ スキップ（小さすぎる）：{gz_url}（{len(r.content)} bytes）\")\n","                continue\n","\n","            with open(local_gz, \"wb\") as f:\n","                f.write(r.content)\n","            print(f\"✅ ダウンロード成功：{gz_url}\")\n","\n","            with gzip.open(local_gz, \"rb\") as f_in, open(local_html, \"wb\") as f_out:\n","                shutil.copyfileobj(f_in, f_out)\n","            print(f\"✅ 解凍成功：{local_html}\")\n","\n","            with open(local_html, encoding=\"utf-8\", errors=\"ignore\") as f:\n","                html = f.read()\n","\n","            found = re.findall(r\"https?://tenhou\\.net/0/\\?log=[\\w\\-]+\", html)\n","            if found:\n","                print(f\"✅ ログ抽出成功（{filename}）：{len(found)} 件\")\n","                converted_links.extend(found)\n","\n","            os.remove(local_gz)\n","            os.remove(local_html)\n","\n","        except Exception as e:\n","            print(f\"⚠️ 処理エラー: {filename} → {e}\")\n","\n","    # URL保存\n","    with open(\"converted_links.txt\", \"w\", encoding=\"utf-8\") as f:\n","        for url in converted_links:\n","            if url.startswith(\"http\"):\n","                f.write(url + \"\\n\")\n","\n","    print(\"✅ converted_links.txt を保存しました（この後 STEP3〜5 に自動接続）\")\n","\n","\n","# ================= STEP3：正規化 =================\n","with open(\"converted_links.txt\", \"r\", encoding=\"utf-8\") as f:\n","    raw_links = [\n","        line.strip()\n","        for line in f\n","        if line.strip().startswith(\"http\") and \"tenhou.net\" in line\n","    ]\n","\n","normalized_links = []\n","for url in raw_links:\n","    url = url.replace(\"/tenhou.net/3/\", \"/tenhou.net/0/\")\n","    url = re.sub(r\"\\?log=\", \"log/?\", url)\n","    url = re.sub(r\"&tw=[0-3]\", \"\", url)\n","    normalized_links.append(url)\n","\n","print(\"✅ 正規化後リンク（例）：\")\n","print(\"\\n\".join(normalized_links[:5]))\n","print(f\"✅ 有効リンク数：{len(normalized_links)} 件（全件処理）\")\n","\n","# ================= STEP4：mjlog ダウンロード =================\n","output_filename = \"mjlog_all.txt\"\n","\n","with open(output_filename, \"w\", encoding=\"utf-8\") as out_file:\n","    for i, url in enumerate(normalized_links):\n","        match = re.search(r\"(?:\\?|/)log[\\/=](.+)\", url)\n","        log_id = match.group(1) if match else f\"log_{i+1}\"\n","\n","        try:\n","            response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n","            response.raise_for_status()\n","            content = response.text.strip()\n","\n","            out_file.write(content + \"\\n\")\n","            out_file.write(\"=\" * 80 + \"\\n\")\n","\n","            print(f\"✅ [{i+1}/10] 保存成功：{log_id}\")\n","        except Exception as e:\n","            print(f\"⚠️ エラー：{log_id} → {e}\")\n","\n","        time.sleep(1)\n","\n","print(f\"✅ 保存完了：{output_filename}\")\n","\n","# ================= STEP5：UNタグ デコード =================\n","def multi_url_decode(s, max_times=5):\n","    for _ in range(max_times):\n","        decoded = urllib.parse.unquote(s)\n","        if decoded == s:\n","            break\n","        s = decoded\n","    return s\n","\n","input_filename = output_filename\n","output_decoded = \"mjlog_all_decoded.txt\"\n","\n","with open(input_filename, \"r\", encoding=\"utf-8\") as f:\n","    content = f.read()\n","\n","logs = content.split(\"=\" * 80)\n","decoded_logs = []\n","\n","for log in logs:\n","    if \"<UN\" not in log:\n","        decoded_logs.append(log)\n","        continue\n","\n","    def replace_names(match):\n","        attr_str = match.group(1)\n","        for i in range(4):\n","            attr_str = re.sub(\n","                rf'n{i}=\"([^\"]+)\"',\n","                lambda m: f'n{i}=\"{multi_url_decode(m.group(1))}\"',\n","                attr_str\n","            )\n","        return f\"<UN {attr_str}>\"\n","\n","    log = re.sub(r\"<UN\\s+([^>]+)>\", replace_names, log)\n","    decoded_logs.append(log)\n","\n","with open(output_decoded, \"w\", encoding=\"utf-8\") as f:\n","    f.write((\"=\" * 80 + \"\\n\").join(decoded_logs))\n","\n","print(f\"🎉 復号完了：{output_decoded}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N17DA3KHOtK8","executionInfo":{"status":"ok","timestamp":1745189214398,"user_tz":-540,"elapsed":29157,"user":{"displayName":"フラポーテ伯爵","userId":"01789154697204439459"}},"outputId":"bf11949b-f9bf-498b-fe62-4c86a556b0df"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["どの方法で牌譜データを取得しますか？\n","い：HTMLファイルをアップロードする\n","ろ：年度別ZIPファイルをダウンロードする\n","は：最近の牌譜（list.cgi）を取得する\n","選択肢を入力してください（い・ろ・は）：は\n","最近の牌譜のどちらを取得しますか？\n","1：直近7日間のリスト\n","2：全過去分（list.cgi?old）\n","選択肢を入力してください（1 または 2）：1\n","⬇️ https://tenhou.net/sc/raw/list.cgi を取得中...\n","✅ list保存完了：tenhou_list_current.txt\n","✅ sccファイル数：536 件（例：['scc2025033000.html.gz', 'scc2025033001.html.gz', 'scc2025033002.html.gz'])\n","✅ ダウンロード成功：https://tenhou.net/sc/raw/dat/scc2025033000.html.gz\n","✅ 解凍成功：scc2025033000.html\n","✅ ログ抽出成功（scc2025033000.html.gz）：63 件\n","✅ ダウンロード成功：https://tenhou.net/sc/raw/dat/scc2025033001.html.gz\n","✅ 解凍成功：scc2025033001.html\n","✅ ログ抽出成功（scc2025033001.html.gz）：46 件\n","✅ ダウンロード成功：https://tenhou.net/sc/raw/dat/scc2025033002.html.gz\n","✅ 解凍成功：scc2025033002.html\n","✅ ログ抽出成功（scc2025033002.html.gz）：24 件\n","✅ ダウンロード成功：https://tenhou.net/sc/raw/dat/scc2025033003.html.gz\n","✅ 解凍成功：scc2025033003.html\n","✅ ログ抽出成功（scc2025033003.html.gz）：20 件\n","✅ ダウンロード成功：https://tenhou.net/sc/raw/dat/scc2025033004.html.gz\n","✅ 解凍成功：scc2025033004.html\n","✅ ログ抽出成功（scc2025033004.html.gz）：15 件\n","✅ ダウンロード成功：https://tenhou.net/sc/raw/dat/scc2025033005.html.gz\n","✅ 解凍成功：scc2025033005.html\n","✅ ログ抽出成功（scc2025033005.html.gz）：12 件\n","✅ ダウンロード成功：https://tenhou.net/sc/raw/dat/scc2025033006.html.gz\n","✅ 解凍成功：scc2025033006.html\n","✅ ログ抽出成功（scc2025033006.html.gz）：17 件\n","✅ ダウンロード成功：https://tenhou.net/sc/raw/dat/scc2025033007.html.gz\n","✅ 解凍成功：scc2025033007.html\n","✅ ログ抽出成功（scc2025033007.html.gz）：18 件\n","✅ ダウンロード成功：https://tenhou.net/sc/raw/dat/scc2025033008.html.gz\n","✅ 解凍成功：scc2025033008.html\n","✅ ログ抽出成功（scc2025033008.html.gz）：20 件\n","✅ ダウンロード成功：https://tenhou.net/sc/raw/dat/scc2025033009.html.gz\n","✅ 解凍成功：scc2025033009.html\n","✅ ログ抽出成功（scc2025033009.html.gz）：30 件\n","✅ converted_links.txt を保存しました（この後 STEP3〜5 に自動接続）\n","✅ 正規化後リンク（例）：\n","http://tenhou.net/0/log/?2025033000gm-00a9-0000-6bb0037f\n","http://tenhou.net/0/log/?2025033000gm-00e1-0000-83210e6e\n","http://tenhou.net/0/log/?2025033000gm-00a9-0000-51eb2ccf\n","http://tenhou.net/0/log/?2025033000gm-00b9-0000-65445de6\n","http://tenhou.net/0/log/?2025033000gm-00a9-0000-b923524a\n","✅ 有効リンク数：265 件（今回は先頭10件のみ処理）\n","✅ [1/10] 保存成功：?2025033000gm-00a9-0000-6bb0037f\n","✅ [2/10] 保存成功：?2025033000gm-00e1-0000-83210e6e\n","✅ [3/10] 保存成功：?2025033000gm-00a9-0000-51eb2ccf\n","✅ [4/10] 保存成功：?2025033000gm-00b9-0000-65445de6\n","✅ [5/10] 保存成功：?2025033000gm-00a9-0000-b923524a\n","✅ [6/10] 保存成功：?2025033000gm-00b9-0000-66cd0120\n","✅ [7/10] 保存成功：?2025033000gm-00b9-0000-cb89abd3\n","✅ [8/10] 保存成功：?2025033000gm-00e1-0000-ecda023b\n","✅ [9/10] 保存成功：?2025033000gm-00a9-0000-a8c74c34\n","✅ [10/10] 保存成功：?2025033000gm-00a9-0000-80193d43\n","✅ 保存完了：mjlog_all.txt\n","🎉 復号完了：mjlog_all_decoded.txt\n"]}]}]}